# Database Schema - Phase II

## Database Provider
**Neon Serverless PostgreSQL**
- Serverless architecture
- Automatic scaling
- SSL encryption
- Connection pooling
- Automatic backups

## Connection
- **Development**: `postgresql://user:password@localhost:5432/todo_dev`
- **Production**: `postgresql://user:password@ep-xxx.us-east-2.aws.neon.tech/todo_prod?sslmode=require`

---

## Tables

### users
User account information (managed by Better Auth).

```sql
CREATE TABLE users (
  id VARCHAR PRIMARY KEY,
  email VARCHAR(255) UNIQUE NOT NULL,
  name VARCHAR(255) NOT NULL,
  password_hash VARCHAR(255) NOT NULL,  -- Better Auth manages hashing
  created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_users_email ON users(email);
```

**Columns**:
| Column | Type | Constraints | Description |
|--------|------|-------------|-------------|
| id | VARCHAR | PRIMARY KEY | Unique user identifier (generated by Better Auth) |
| email | VARCHAR(255) | UNIQUE, NOT NULL | User's email address (login credential) |
| name | VARCHAR(255) | NOT NULL | User's display name |
| password_hash | VARCHAR(255) | NOT NULL | Bcrypt-hashed password (Better Auth handles) |
| created_at | TIMESTAMP | DEFAULT NOW() | Account creation timestamp |

**Indexes**:
- `PRIMARY KEY (id)`: Primary key index
- `idx_users_email`: Index on email for fast lookup during login

**Constraints**:
- Email must be unique across all users
- Email must be valid format (enforced by application)
- Password must be hashed (enforced by Better Auth)

---

### tasks
Todo task items created by users.

```sql
CREATE TABLE tasks (
  id SERIAL PRIMARY KEY,
  user_id VARCHAR NOT NULL REFERENCES users(id) ON DELETE CASCADE,
  title VARCHAR(200) NOT NULL,
  description TEXT,
  completed BOOLEAN DEFAULT FALSE,
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_tasks_user_id ON tasks(user_id);
CREATE INDEX idx_tasks_completed ON tasks(completed);
CREATE INDEX idx_tasks_user_completed ON tasks(user_id, completed);
```

**Columns**:
| Column | Type | Constraints | Description |
|--------|------|-------------|-------------|
| id | SERIAL | PRIMARY KEY | Auto-incrementing task ID |
| user_id | VARCHAR | NOT NULL, FOREIGN KEY | User who owns this task |
| title | VARCHAR(200) | NOT NULL | Task title/description |
| description | TEXT | NULL | Optional detailed description |
| completed | BOOLEAN | DEFAULT FALSE | Task completion status |
| created_at | TIMESTAMP | DEFAULT NOW() | Task creation timestamp |
| updated_at | TIMESTAMP | DEFAULT NOW() | Last modification timestamp |

**Indexes**:
- `PRIMARY KEY (id)`: Primary key index
- `idx_tasks_user_id`: Index on user_id for filtering by user
- `idx_tasks_completed`: Index on completed for status filtering
- `idx_tasks_user_completed`: Composite index for common query pattern (user + status)

**Foreign Keys**:
- `user_id REFERENCES users(id) ON DELETE CASCADE`: Tasks deleted when user is deleted

**Constraints**:
- Title cannot be empty (enforced by NOT NULL)
- Title max 200 characters (enforced by VARCHAR(200))
- Description max 1000 characters (enforced by application)
- user_id must reference valid user

---

## Relationships

### One-to-Many: User → Tasks
```
users (1) ──────< (∞) tasks
  id                user_id
```

**Description**:
- One user can have many tasks
- Each task belongs to exactly one user
- Cascade delete: When user is deleted, all their tasks are deleted

**SQLModel Representation** (Backend):
```python
from sqlmodel import SQLModel, Field, Relationship
from typing import Optional

class User(SQLModel, table=True):
    __tablename__ = "users"

    id: str = Field(primary_key=True)
    email: str = Field(unique=True, index=True, max_length=255)
    name: str = Field(max_length=255)
    password_hash: str = Field(max_length=255)
    created_at: datetime = Field(default_factory=datetime.utcnow)

    tasks: list["Task"] = Relationship(back_populates="user", cascade_delete=True)

class Task(SQLModel, table=True):
    __tablename__ = "tasks"

    id: Optional[int] = Field(default=None, primary_key=True)
    user_id: str = Field(foreign_key="users.id", index=True)
    title: str = Field(max_length=200)
    description: Optional[str] = Field(default=None, max_length=1000)
    completed: bool = Field(default=False, index=True)
    created_at: datetime = Field(default_factory=datetime.utcnow)
    updated_at: datetime = Field(default_factory=datetime.utcnow)

    user: User = Relationship(back_populates="tasks")
```

---

## Indexes Strategy

### Why These Indexes?

**idx_users_email**:
- **Query**: `SELECT * FROM users WHERE email = ?` (login)
- **Frequency**: Every login attempt
- **Impact**: Critical for authentication performance

**idx_tasks_user_id**:
- **Query**: `SELECT * FROM tasks WHERE user_id = ?` (list tasks)
- **Frequency**: Every page load
- **Impact**: Essential for multi-user performance

**idx_tasks_completed**:
- **Query**: `SELECT * FROM tasks WHERE completed = ?` (filter by status)
- **Frequency**: When filtering tasks
- **Impact**: Moderate performance benefit

**idx_tasks_user_completed** (Composite):
- **Query**: `SELECT * FROM tasks WHERE user_id = ? AND completed = ?` (filter user's tasks by status)
- **Frequency**: Very common (default query pattern)
- **Impact**: High performance benefit for most queries

### Index Sizes (Estimated)
For 1,000 users with 100 tasks each (100,000 tasks total):
- `idx_users_email`: ~50 KB
- `idx_tasks_user_id`: ~2 MB
- `idx_tasks_completed`: ~2 MB
- `idx_tasks_user_completed`: ~4 MB

**Total Index Overhead**: ~8 MB (negligible)

---

## Data Integrity

### Referential Integrity
- Foreign key `tasks.user_id → users.id` enforced
- Cascade delete ensures orphan prevention
- Cannot create task without valid user

### Data Validation (Application Layer)
- Email format validation (frontend + backend)
- Password strength validation (frontend + backend)
- Title length validation (1-200 chars)
- Description length validation (0-1000 chars)
- User ownership verification on all operations

---

## Migrations

### Migration Tool
**Alembic** (Python database migration tool)

### Initial Migration
```bash
# Generate migration
alembic revision --autogenerate -m "Initial schema: users and tasks"

# Apply migration
alembic upgrade head
```

### Migration Files
```
backend/migrations/
├── env.py
└── versions/
    └── 001_initial_schema.py
```

### Example Migration
```python
# versions/001_initial_schema.py

def upgrade() -> None:
    # Create users table
    op.create_table(
        'users',
        sa.Column('id', sa.String(), nullable=False),
        sa.Column('email', sa.String(length=255), nullable=False),
        sa.Column('name', sa.String(length=255), nullable=False),
        sa.Column('password_hash', sa.String(length=255), nullable=False),
        sa.Column('created_at', sa.DateTime(), nullable=True),
        sa.PrimaryKeyConstraint('id'),
        sa.UniqueConstraint('email')
    )
    op.create_index('idx_users_email', 'users', ['email'])

    # Create tasks table
    op.create_table(
        'tasks',
        sa.Column('id', sa.Integer(), autoincrement=True, nullable=False),
        sa.Column('user_id', sa.String(), nullable=False),
        sa.Column('title', sa.String(length=200), nullable=False),
        sa.Column('description', sa.Text(), nullable=True),
        sa.Column('completed', sa.Boolean(), nullable=True),
        sa.Column('created_at', sa.DateTime(), nullable=True),
        sa.Column('updated_at', sa.DateTime(), nullable=True),
        sa.ForeignKeyConstraint(['user_id'], ['users.id'], ondelete='CASCADE'),
        sa.PrimaryKeyConstraint('id')
    )
    op.create_index('idx_tasks_user_id', 'tasks', ['user_id'])
    op.create_index('idx_tasks_completed', 'tasks', ['completed'])
    op.create_index('idx_tasks_user_completed', 'tasks', ['user_id', 'completed'])

def downgrade() -> None:
    op.drop_table('tasks')
    op.drop_table('users')
```

---

## Connection Pooling

### Configuration
```python
# backend/app/database.py

from sqlmodel import create_engine, Session

engine = create_engine(
    DATABASE_URL,
    pool_size=5,           # Maintain 5 connections
    max_overflow=10,       # Allow 10 additional connections
    pool_pre_ping=True,    # Verify connections before use
    pool_recycle=3600,     # Recycle connections after 1 hour
    echo=False             # Don't log SQL (enable for debugging)
)
```

**Benefits**:
- Reuse existing connections (faster)
- Limit concurrent connections (protect database)
- Auto-recover from connection failures

---

## Query Patterns

### Common Queries

**List user's tasks (with filtering)**:
```sql
-- All tasks
SELECT * FROM tasks
WHERE user_id = 'user_abc123'
ORDER BY created_at DESC;

-- Only pending
SELECT * FROM tasks
WHERE user_id = 'user_abc123' AND completed = FALSE
ORDER BY created_at DESC;

-- Only completed
SELECT * FROM tasks
WHERE user_id = 'user_abc123' AND completed = TRUE
ORDER BY created_at DESC;
```
**Uses**: `idx_tasks_user_completed` (composite index)

**Get task by ID (with ownership check)**:
```sql
SELECT * FROM tasks
WHERE id = 1 AND user_id = 'user_abc123';
```
**Uses**: Primary key + `idx_tasks_user_id`

**Dashboard statistics**:
```sql
-- Count total, pending, completed
SELECT
  COUNT(*) as total,
  SUM(CASE WHEN completed = FALSE THEN 1 ELSE 0 END) as pending,
  SUM(CASE WHEN completed = TRUE THEN 1 ELSE 0 END) as completed
FROM tasks
WHERE user_id = 'user_abc123';
```
**Uses**: `idx_tasks_user_id`

---

## Performance Considerations

### Query Performance Targets
- List tasks: < 50ms
- Create task: < 30ms
- Update task: < 30ms
- Delete task: < 20ms
- Dashboard stats: < 100ms

### Optimization Strategies
1. **Use indexes** for all WHERE and ORDER BY columns
2. **Limit result sets** (pagination for large lists)
3. **Connection pooling** to avoid connection overhead
4. **Prepared statements** (SQLModel handles this)
5. **Avoid N+1 queries** (eager loading with Relationship)

### Scaling Considerations
- Current design supports 10,000+ users
- Each user can have 10,000+ tasks
- Database size: ~100 MB per 10,000 users (with 100 tasks each)
- Read-heavy workload (90% reads, 10% writes)
- Horizontal scaling ready (stateless queries)

---

## Backup Strategy

### Neon Automatic Backups
- **Frequency**: Continuous (point-in-time recovery)
- **Retention**: 7 days (free tier)
- **Recovery**: Restore to any point within retention period

### Manual Backups (Optional)
```bash
# Dump database
pg_dump $DATABASE_URL > backup.sql

# Restore database
psql $DATABASE_URL < backup.sql
```

---

## Security

### Connection Security
- SSL/TLS encryption required
- No plaintext connections allowed
- Connection string stored in environment variables

### Data Security
- Passwords hashed with bcrypt (Better Auth)
- No sensitive data in logs
- User data isolation enforced

### Access Control
- Application-level authorization (JWT)
- Row-level security via user_id filtering
- No direct database access from frontend

---

**Schema Version**: 1.0.0
**Last Updated**: 2025-12-30
**Status**: ✅ Complete for Phase II
**Future**: Phase III will add `conversations` and `messages` tables
